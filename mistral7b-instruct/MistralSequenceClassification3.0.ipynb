{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/josebambora/mistral-v1?scriptVersionId=176042241\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install -q -U torch=='2.0.0'","metadata":{"execution":{"iopub.status.busy":"2024-05-06T15:59:57.535482Z","iopub.execute_input":"2024-05-06T15:59:57.535761Z","iopub.status.idle":"2024-05-06T16:01:53.311485Z","shell.execute_reply.started":"2024-05-06T15:59:57.535737Z","shell.execute_reply":"2024-05-06T16:01:53.310372Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U accelerate=='0.25.0' peft=='0.7.1' bitsandbytes=='0.41.3.post2' transformers=='4.36.1' trl=='0.7.4'","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:01:53.313295Z","iopub.execute_input":"2024-05-06T16:01:53.313612Z","iopub.status.idle":"2024-05-06T16:02:22.812264Z","shell.execute_reply.started":"2024-05-06T16:01:53.313586Z","shell.execute_reply":"2024-05-06T16:02:22.811195Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:02:22.813589Z","iopub.execute_input":"2024-05-06T16:02:22.813883Z","iopub.status.idle":"2024-05-06T16:02:35.126585Z","shell.execute_reply.started":"2024-05-06T16:02:22.813856Z","shell.execute_reply":"2024-05-06T16:02:35.125619Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import Dataset, concatenate_datasets\nfrom peft import LoraConfig, PeftConfig\nfrom trl import SFTTrainer\nfrom transformers import (AutoModelForCausalLM,\n                          AutoTokenizer,\n                          BitsAndBytesConfig,\n                          TrainingArguments,\n                          pipeline,\n                          logging)\nfrom sklearn.metrics import (accuracy_score,\n                             classification_report,\n                             confusion_matrix)\nfrom sklearn.model_selection import train_test_split\nfrom datasets import load_dataset\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:02:35.128691Z","iopub.execute_input":"2024-05-06T16:02:35.129005Z","iopub.status.idle":"2024-05-06T16:02:54.685644Z","shell.execute_reply.started":"2024-05-06T16:02:35.128977Z","shell.execute_reply":"2024-05-06T16:02:54.684801Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-05-06 16:02:43.964935: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-06 16:02:43.965040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-06 16:02:44.099080: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"notebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:03:47.225468Z","iopub.execute_input":"2024-05-06T16:03:47.226272Z","iopub.status.idle":"2024-05-06T16:03:47.247698Z","shell.execute_reply.started":"2024-05-06T16:03:47.226241Z","shell.execute_reply":"2024-05-06T16:03:47.24663Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"926175258827414589e5764f8851408b"}},"metadata":{}}]},{"cell_type":"code","source":"os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:16.472865Z","iopub.execute_input":"2024-05-06T16:04:16.473253Z","iopub.status.idle":"2024-05-06T16:04:16.478237Z","shell.execute_reply.started":"2024-05-06T16:04:16.473224Z","shell.execute_reply":"2024-05-06T16:04:16.477165Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def generate_prompt(data_point):\n    label = 'positive'\n    if data_point[\"label\"] != 1:\n        label = 'negative'\n    res = f\"\"\"\n            [INST]Analyze the sentiment of the news headline enclosed in square brackets,\n            determine if it is positive, or negative, and return the answer as\n            the corresponding sentiment label \"positive\" or \"negative\"[/INST]\n\n            [{data_point[\"text\"]}] = {label}\"\"\".strip()\n    return re.sub(r'\\s+', ' ', res)\n\ndef generate_test_prompt(data_point):\n    res = f\"\"\"\n            [INST]Analyze the sentiment of the news headline enclosed in square brackets,\n            determine if it is positive, or negative, and return the answer as\n            the corresponding sentiment label \"positive\" or \"negative\"[/INST]\n\n            [{data_point[\"text\"]}] = \"\"\".strip()\n    return re.sub(r'\\s+', ' ', res)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:17.973935Z","iopub.execute_input":"2024-05-06T16:04:17.975064Z","iopub.status.idle":"2024-05-06T16:04:17.981135Z","shell.execute_reply.started":"2024-05-06T16:04:17.975033Z","shell.execute_reply":"2024-05-06T16:04:17.980106Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def select(data,label_result,range_num):\n    return data.filter(lambda example: example['label'] == label_result).shuffle(seed=42).select(range(range_num))\n\ndef generate_data(data,train):\n    if train:\n        return data.shuffle(seed=42).map(lambda elem : {'text': generate_prompt(elem)})\n    else:\n        return data.shuffle(seed=42).map(lambda elem : {'text': generate_test_prompt(elem)})","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:20.183225Z","iopub.execute_input":"2024-05-06T16:04:20.183599Z","iopub.status.idle":"2024-05-06T16:04:20.189796Z","shell.execute_reply.started":"2024-05-06T16:04:20.183557Z","shell.execute_reply":"2024-05-06T16:04:20.188804Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def prepare_data():\n    imdb = load_dataset('imdb')\n\n    positive_rows = select(imdb['train'],1,200)\n    negative_rows = select(imdb['train'],0,200)\n\n    positive_rows_train = positive_rows.select(indices=range(150))\n    negative_rows_train = negative_rows.select(indices=range(150))\n    positive_rows_eval  = positive_rows.select(indices=range(150, 200))\n    negative_rows_eval  = negative_rows.select(indices=range(150, 200))\n    positive_rows_test  = select(imdb['test'],1,50)\n    negative_rows_test  = select(imdb['test'],0,50)\n\n    selected_rows_train = concatenate_datasets([positive_rows_train, negative_rows_train])\n    selected_rows_eval  = concatenate_datasets([positive_rows_eval, negative_rows_eval])\n    selected_rows_test  = concatenate_datasets([positive_rows_test, negative_rows_test])\n\n    data_train = generate_data(selected_rows_train,True)\n    data_eval  = generate_data(selected_rows_eval,True)\n    data_test  = generate_data(selected_rows_test,False)\n\n    X_test = pd.DataFrame(data_test)\n    y_true= list(X_test['label'])\n    X_test.drop(['label'],axis=1,inplace=True)\n\n    return data_train, data_eval, data_test, X_test, y_true","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:20.933727Z","iopub.execute_input":"2024-05-06T16:04:20.934128Z","iopub.status.idle":"2024-05-06T16:04:20.943665Z","shell.execute_reply.started":"2024-05-06T16:04:20.934099Z","shell.execute_reply":"2024-05-06T16:04:20.942514Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data_train, data_eval, data_test, X_test, y_true = prepare_data()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:21.856812Z","iopub.execute_input":"2024-05-06T16:04:21.857193Z","iopub.status.idle":"2024-05-06T16:04:29.303581Z","shell.execute_reply.started":"2024-05-06T16:04:21.857162Z","shell.execute_reply":"2024-05-06T16:04:29.302742Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"654b71677aab44babaf135f1993129ad"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.0M/21.0M [00:00<00:00, 61.6MB/s]\nDownloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20.5M/20.5M [00:00<00:00, 68.1MB/s]\nDownloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.0M/42.0M [00:00<00:00, 125MB/s] \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0c57f43f72f40249d45b9207b4a70bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed8ba7a323004601989767d8e2beba9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18c3a788c3414d9080de063936cf6308"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54947b6cd8e2462c93854ee65fa6756a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d72f7d7547e64f9890c7c5e18598c4c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cd6989adc6a4f268a0eab1637136b86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77165f0c5d0a49e0bb1f1e06a0e7f224"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/300 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac91f190c4bf48c5ba5f2ee098606c23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ae33fd3bf27405ba3f13a76a2a31e54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81cf8069ed814bcab1dc0142820a33cd"}},"metadata":{}}]},{"cell_type":"code","source":"def accuracy_for_label(y_true, y_pred, label):\n    label_indices = [i for i, y in enumerate(y_true) if y == label]\n    label_y_true = [y_true[i] for i in label_indices]\n    label_y_pred = [y_pred[i] for i in label_indices]\n    return accuracy_score(label_y_true, label_y_pred)\n\ndef evaluate(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    # Overall Accuracy\n    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n    print(f'Accuracy: {accuracy:.3f}')\n\n    # Accuracy for each label\n    accuracy_negative = accuracy_for_label(y_true,y_pred,0)\n    accuracy_positive = accuracy_for_label(y_true,y_pred,1)\n\n    print(f'Accuracy for negative reviews: {accuracy_negative:.3f}')\n    print(f'Accuracy for positive reviews: {accuracy_positive:.3f}')\n\n    # Generate classification report\n    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n    print('\\nClassification Report:')\n    print(class_report)\n\n    # Generate confusion matrix\n    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1])\n    print('\\nConfusion Matrix:')\n    print(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:31.831323Z","iopub.execute_input":"2024-05-06T16:04:31.831728Z","iopub.status.idle":"2024-05-06T16:04:31.841638Z","shell.execute_reply.started":"2024-05-06T16:04:31.831694Z","shell.execute_reply":"2024-05-06T16:04:31.839453Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def generate_response(prompt,model,tokenizer):\n    pipe = pipeline(task=\"text-generation\",\n                        model=model,\n                        tokenizer=tokenizer,\n                        max_new_tokens = 1,\n                        temperature = 0.0)\n    result = pipe(prompt, pad_token_id=pipe.tokenizer.eos_token_id)\n    return result[0]['generated_text'].split(\"=\")[-1].lower()\n\ndef predict(X_test, model, tokenizer):\n    y_pred = []\n    for i in tqdm(range(len(X_test))):\n        prompt = X_test.iloc[i][\"text\"]\n        answer = generate_response(prompt,model,tokenizer)\n        if \"positive\" in answer:\n            y_pred.append(1)\n        else:\n            y_pred.append(0)\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:33.26315Z","iopub.execute_input":"2024-05-06T16:04:33.263513Z","iopub.status.idle":"2024-05-06T16:04:33.271219Z","shell.execute_reply.started":"2024-05-06T16:04:33.263485Z","shell.execute_reply":"2024-05-06T16:04:33.270123Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n    compute_dtype = getattr(torch, \"float16\")\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_use_double_quant=False,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=compute_dtype,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        device_map=\"auto\",\n        quantization_config=bnb_config,\n    )\n    model.config.use_cache = False\n    model.config.pretraining_tp = 1\n    tokenizer = AutoTokenizer.from_pretrained(model_name,\n                                              trust_remote_code=True,\n                                              padding_side=\"left\",\n                                              add_bos_token=True,\n                                              add_eos_token=True,\n                                            )\n    tokenizer.pad_token = tokenizer.eos_token\n    return (model,tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:34.083345Z","iopub.execute_input":"2024-05-06T16:04:34.083744Z","iopub.status.idle":"2024-05-06T16:04:34.090687Z","shell.execute_reply.started":"2024-05-06T16:04:34.083713Z","shell.execute_reply":"2024-05-06T16:04:34.089642Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model,tokenizer = get_model()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:34.84902Z","iopub.execute_input":"2024-05-06T16:04:34.84953Z","iopub.status.idle":"2024-05-06T16:07:08.598994Z","shell.execute_reply.started":"2024-05-06T16:04:34.849493Z","shell.execute_reply":"2024-05-06T16:07:08.598083Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1d5ea32ad2d4fa3b8274cdf857209b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ab65d16298e4293b3641a0ab7658218"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1078d9df868483384390ae676814150"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2067deef33c34b6ebd43fdc3b099330c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc55365d00a43028c73507e732f84d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2764da9b87040e895817f5dfa68cbb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcb262b080ff46629fb37e93aa9009d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb936a2933fd44acbcf1bebd4e63fb84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e00496ce3f4440d3b2e7a3b7bc88fb3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eafd1eec77ae42f684c3c60977298896"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9315aeaa251a43689c16726c1f69cc69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6edd0ccb196a461597818ac4555b1a51"}},"metadata":{}}]},{"cell_type":"code","source":"y_pred = predict(X_test, model, tokenizer)\nevaluate(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:07:23.920552Z","iopub.execute_input":"2024-05-06T16:07:23.920958Z","iopub.status.idle":"2024-05-06T16:08:09.29469Z","shell.execute_reply.started":"2024-05-06T16:07:23.920926Z","shell.execute_reply":"2024-05-06T16:08:09.29372Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:45<00:00,  2.21it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.630\nAccuracy for negative reviews: 0.980\nAccuracy for positive reviews: 0.280\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.58      0.98      0.73        50\n           1       0.93      0.28      0.43        50\n\n    accuracy                           0.63       100\n   macro avg       0.75      0.63      0.58       100\nweighted avg       0.75      0.63      0.58       100\n\n\nConfusion Matrix:\n[[49  1]\n [36 14]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_configuration():\n    peft_config = LoraConfig(\n        lora_alpha=16,\n        lora_dropout=0.1,\n        r=64,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\",\n    )\n\n    training_arguments = TrainingArguments(\n        output_dir=\"mistral_retrained\",\n        num_train_epochs=4,\n        per_device_train_batch_size=1,\n        gradient_accumulation_steps=4,\n        optim=\"paged_adamw_32bit\",\n        save_steps=0,\n        logging_steps=25,\n        learning_rate=2e-4,\n        weight_decay=0.001,\n        fp16=True,\n        max_grad_norm=0.3,\n        warmup_ratio=0.03,\n        group_by_length=True,\n        lr_scheduler_type=\"cosine\",\n        report_to=\"tensorboard\",\n        evaluation_strategy=\"epoch\"\n    )\n\n    trainer = SFTTrainer(\n        model=model,\n        train_dataset=data_train,\n        eval_dataset=data_eval,\n        peft_config=peft_config,\n        dataset_text_field=\"text\",\n        tokenizer=tokenizer,\n        args=training_arguments,\n        packing=False,\n        max_seq_length=512,\n    )\n    return trainer","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:08:09.29652Z","iopub.execute_input":"2024-05-06T16:08:09.296854Z","iopub.status.idle":"2024-05-06T16:08:09.304122Z","shell.execute_reply.started":"2024-05-06T16:08:09.296827Z","shell.execute_reply":"2024-05-06T16:08:09.303256Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"trainer = train_configuration()\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:08:09.305218Z","iopub.execute_input":"2024-05-06T16:08:09.305544Z","iopub.status.idle":"2024-05-06T16:31:42.765206Z","shell.execute_reply.started":"2024-05-06T16:08:09.305512Z","shell.execute_reply":"2024-05-06T16:31:42.764215Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/300 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86885f23664c4dc3abfef89ced57386c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7170ff036c874b58abb2b43cf1ac034e"}},"metadata":{}},{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [300/300 23:26, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.063300</td>\n      <td>2.109846</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.923800</td>\n      <td>2.115145</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.881100</td>\n      <td>2.136935</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.771400</td>\n      <td>2.152300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=300, training_loss=1.978971265157064, metrics={'train_runtime': 1411.8261, 'train_samples_per_second': 0.85, 'train_steps_per_second': 0.212, 'total_flos': 1.6838246320078848e+16, 'train_loss': 1.978971265157064, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = predict(X_test, model, tokenizer)\nevaluate(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:32:01.790112Z","iopub.execute_input":"2024-05-06T16:32:01.790518Z","iopub.status.idle":"2024-05-06T16:32:54.449276Z","shell.execute_reply.started":"2024-05-06T16:32:01.790487Z","shell.execute_reply":"2024-05-06T16:32:54.448274Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:52<00:00,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.940\nAccuracy for negative reviews: 0.940\nAccuracy for positive reviews: 0.940\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.94      0.94      0.94        50\n           1       0.94      0.94      0.94        50\n\n    accuracy                           0.94       100\n   macro avg       0.94      0.94      0.94       100\nweighted avg       0.94      0.94      0.94       100\n\n\nConfusion Matrix:\n[[47  3]\n [ 3 47]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:34:10.969578Z","iopub.execute_input":"2024-05-06T16:34:10.970075Z","iopub.status.idle":"2024-05-06T16:34:15.726579Z","shell.execute_reply.started":"2024-05-06T16:34:10.970039Z","shell.execute_reply":"2024-05-06T16:34:15.725519Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80ebed2309c2467fa3c5e7c83673e27d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1715011690.1c87e7b223c2.34.0:   0%|          | 0.00/8.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"effe85fb58fc41ccbf200bced47bb259"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e285fac205c045b88cba2acbb1e4b665"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/109M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"142fe5b86c014cdcb0484b6c9f0ad20c"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/JoseBambora/mistral_retrained/commit/121fa6352209c44502d28e165ee21ba48a66de04', commit_message='End of training', commit_description='', oid='121fa6352209c44502d28e165ee21ba48a66de04', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}